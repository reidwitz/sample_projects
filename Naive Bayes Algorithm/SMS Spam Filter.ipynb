{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMS Spam Filter\n",
    "\n",
    "In this project, we're using a dataset of SMS messages that have been categorized as 'spam' or 'not spam' in order to develop a spam filter using the Naive Bayes algorithm. Our goal is to achieve accuracy of 80%, meaning that more than 80% of new messages will be classified correctly.\n",
    "\n",
    "The dataset comes from Tiago A. Almeida and José María Gómez Hidalgo, and can be found [here](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). It includes 5,572 SMS messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Start by reading the dataset and getting to know it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sms = pd.read_csv('SMSSpamCollection', sep = '\\t', header=None, names=['Label','SMS'])\n",
    "\n",
    "print(sms.shape)\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: Label, dtype: int64\n",
      "ham     0.865937\n",
      "spam    0.134063\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(sms['Label'].value_counts())\n",
    "print(sms['Label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that about 13% of the messages are spam. This isn't surprizing since most messages we receive are genuine ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set and Testing Set\n",
    "\n",
    "We're going to split our data into two sets - one to train the program and one to test the accuracy.\n",
    "\n",
    "We will use 80% for training and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "randomized = sms.sample(frac=1,random_state=1)\n",
    "\n",
    "training_index = round(len(randomized)*0.8)\n",
    "\n",
    "train = randomized[:training_index].reset_index(drop=True)\n",
    "test = randomized[training_index:].reset_index(drop=True)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: Label, dtype: float64\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.Label.value_counts(normalize=True))\n",
    "print(test.Label.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the ratio of spam to ham has remained consistent in each subset with the overall dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation and Case\n",
    "\n",
    "In order to process the data effectively, we need to strip punctuation and uppercase characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.SMS = train.SMS.str.replace('\\W',' ').str.lower()\n",
    "test.SMS = test.SMS.str.replace('\\W',' ').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vocabulary\n",
    "\n",
    "We need a list of all the unique words in our training set - we'll call this the vocabulary of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.SMS = train.SMS.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2   ham                    [welp, apparently, he, retired]\n",
       "3   ham                                           [havent]\n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "\n",
    "for msg in train.SMS:\n",
    "    for word in msg:\n",
    "        vocab.append(word)\n",
    "vocab = list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 7,783 unqiue words in our training set of sms's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation\n",
    "\n",
    "We now need to convert the unique vocabulary into columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {x: [0] * len(train.SMS) for x in vocab}\n",
    "\n",
    "for index, msg in enumerate(train.SMS):\n",
    "    for word in msg:\n",
    "        word_counts_per_sms[word][index] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blimey</th>\n",
       "      <th>mornings</th>\n",
       "      <th>interested</th>\n",
       "      <th>acnt</th>\n",
       "      <th>following</th>\n",
       "      <th>islands</th>\n",
       "      <th>disconnect</th>\n",
       "      <th>girlie</th>\n",
       "      <th>ah</th>\n",
       "      <th>uncle</th>\n",
       "      <th>...</th>\n",
       "      <th>intend</th>\n",
       "      <th>concern</th>\n",
       "      <th>brain</th>\n",
       "      <th>proof</th>\n",
       "      <th>manage</th>\n",
       "      <th>mandy</th>\n",
       "      <th>wish</th>\n",
       "      <th>09071512433</th>\n",
       "      <th>recession</th>\n",
       "      <th>finn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   blimey  mornings  interested  acnt  following  islands  disconnect  girlie  \\\n",
       "0       0         0           0     0          0        0           0       0   \n",
       "1       0         0           0     0          0        0           0       0   \n",
       "2       0         0           0     0          0        0           0       0   \n",
       "3       0         0           0     0          0        0           0       0   \n",
       "4       0         0           0     0          0        0           0       0   \n",
       "\n",
       "   ah  uncle  ...  intend  concern  brain  proof  manage  mandy  wish  \\\n",
       "0   0      0  ...       0        0      0      0       0      0     0   \n",
       "1   0      0  ...       0        0      0      0       0      0     0   \n",
       "2   0      0  ...       0        0      0      0       0      0     0   \n",
       "3   0      0  ...       0        0      0      0       0      0     0   \n",
       "4   0      0  ...       0        0      0      0       0      0     0   \n",
       "\n",
       "   09071512433  recession  finn  \n",
       "0            0          0     0  \n",
       "1            0          0     0  \n",
       "2            0          0     0  \n",
       "3            0          0     0  \n",
       "4            0          0     0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>blimey</th>\n",
       "      <th>mornings</th>\n",
       "      <th>interested</th>\n",
       "      <th>acnt</th>\n",
       "      <th>following</th>\n",
       "      <th>islands</th>\n",
       "      <th>disconnect</th>\n",
       "      <th>girlie</th>\n",
       "      <th>...</th>\n",
       "      <th>intend</th>\n",
       "      <th>concern</th>\n",
       "      <th>brain</th>\n",
       "      <th>proof</th>\n",
       "      <th>manage</th>\n",
       "      <th>mandy</th>\n",
       "      <th>wish</th>\n",
       "      <th>09071512433</th>\n",
       "      <th>recession</th>\n",
       "      <th>finn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  blimey  mornings  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]       0         0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...       0         0   \n",
       "2   ham                    [welp, apparently, he, retired]       0         0   \n",
       "3   ham                                           [havent]       0         0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...       0         0   \n",
       "\n",
       "   interested  acnt  following  islands  disconnect  girlie  ...  intend  \\\n",
       "0           0     0          0        0           0       0  ...       0   \n",
       "1           0     0          0        0           0       0  ...       0   \n",
       "2           0     0          0        0           0       0  ...       0   \n",
       "3           0     0          0        0           0       0  ...       0   \n",
       "4           0     0          0        0           0       0  ...       0   \n",
       "\n",
       "   concern  brain  proof  manage  mandy  wish  09071512433  recession  finn  \n",
       "0        0      0      0       0      0     0            0          0     0  \n",
       "1        0      0      0       0      0     0            0          0     0  \n",
       "2        0      0      0       0      0     0            0          0     0  \n",
       "3        0      0      0       0      0     0            0          0     0  \n",
       "4        0      0      0       0      0     0            0          0     0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = pd.concat([train, word_counts],axis=1)\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font size=\"2.5\"> The Naive Bayes algorithm relies on resolving these two equations in order to classify new messages:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    " <font size=\"4\">$ P(Spam| w_1,w_2,...,w_n) \\propto P(Spam)*    \\prod_{i=1}^{n} P(w_i|Spam)     $\n",
    "\n",
    "$ P(Ham| w_1,w_2,...,w_n) \\propto P(Ham)*    \\prod_{i=1}^{n} P(w_i|Ham)     $\n",
    "\n",
    "    \n",
    "&nbsp;\n",
    "\n",
    " <font size=\"2.5\"> In order to calculate $P(w_i|Ham)$ and $P(w_i|Spam)$, we need to use these equations:\n",
    "\n",
    "     \n",
    "&nbsp;\n",
    "\n",
    "<font size=\"4\"> $ P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha * N_{Vocabulary}} $\n",
    "    \n",
    "$ P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha * N_{Vocabulary}} $\n",
    "\n",
    "&nbsp;    \n",
    "    \n",
    "<font size=\"2.5\"> We must calculate the following constants in order to use the Naive Bayes algorithm\n",
    "\n",
    "- P(Spam)\n",
    "- P(Ham)\n",
    "- N(Spam) -- note that this is the total number of words in all spam messages\n",
    "- N(Ham) -- note that this is the total number of words in all ham messages\n",
    "- N(Vocabulary)\n",
    "- Alpha\n",
    "    \n",
    " We will set $\\alpha = 1$ and calculate the remaining constants below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = train_clean.Label.value_counts(normalize= True)['spam']\n",
    "p_ham = train_clean.Label.value_counts(normalize= True)['ham']\n",
    "\n",
    "\n",
    "spam = train_clean[train_clean.Label=='spam']\n",
    "ham = train_clean[train_clean.Label=='ham']\n",
    "\n",
    "n_spam = 0\n",
    "\n",
    "for x in spam['SMS']:\n",
    "    n_spam += len(x)\n",
    "    \n",
    "n_ham = 0\n",
    "for x in ham['SMS']:\n",
    "    n_ham += len(x)\n",
    "\n",
    "n_vocab = len(vocab)\n",
    "alpha=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "Now that we've found our constants, we need to calculate our parameters $ P(w_i|Spam) $ and $ P(w_i|Ham) $. Each parameter represents a conditional probability associated with each word in our vocabulary. The formulas used are as follows:\n",
    "&nbsp; \n",
    "<font size=\"4\">\n",
    "    \n",
    "$ P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam}+\\alpha*N_{Vocabulary}} $\n",
    "    \n",
    "$ P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham}+\\alpha*N_{Vocabulary}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_spam = {x:0 for x in vocab}\n",
    "param_ham = {x:0 for x in vocab}\n",
    "\n",
    "for word in vocab:\n",
    "    p_word_given_spam = (spam[word].sum() + alpha) / (n_spam + alpha*n_vocab)\n",
    "    param_spam[word] = p_word_given_spam\n",
    "\n",
    "    p_word_given_ham = (ham[word].sum() + alpha) / (n_ham + alpha*n_vocab)\n",
    "    param_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Function\n",
    "\n",
    "The following function uses the Naive Bayes algorithm to classify incoming text messages based on the classifications in the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    # Clean incoming words to remove punctuation, lower the case and split into a list of words\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    # Initialize probabilities of spam and ham\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    \n",
    "    # Loop over each word in the input message and if the word is present in our vocab, \n",
    "    # multiply p_spam and p_ham by the parameter for that word\n",
    "    for word in message:\n",
    "        if word in param_spam:\n",
    "            p_spam_given_message *= param_spam[word]\n",
    "        if word in param_ham:\n",
    "            p_ham_given_message *= param_ham[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Check\n",
    "\n",
    "Before we test the algorithm with our test data, let's do a quick sanity check on two messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify ('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify (\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Filter\n",
    "\n",
    "The results of our initial check look good, but let's test our data more thoroughly on our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test(message):\n",
    "\n",
    "    # Clean incoming words to remove punctuation, lower the case and split into a list of words\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    # Initialize probabilities of spam and ham\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    \n",
    "    # Loop over each word in the input message and if the word is present in our vocab, \n",
    "    # multiply p_spam and p_ham by the parameter for that word\n",
    "    for word in message:\n",
    "        if word in param_spam:\n",
    "            p_spam_given_message *= param_spam[word]\n",
    "        if word in param_ham:\n",
    "            p_ham_given_message *= param_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to add a column to our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>later i guess  i needa do mcat study too</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>but i haf enuff space got like 4 mb</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 10 mths  update to latest oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>all sounds good  fingers   makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>all done  all handed in  don t know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS prediction\n",
       "0   ham          later i guess  i needa do mcat study too         ham\n",
       "1   ham             but i haf enuff space got like 4 mb           ham\n",
       "2  spam  had your mobile 10 mths  update to latest oran...       spam\n",
       "3   ham  all sounds good  fingers   makes it difficult ...        ham\n",
       "4   ham  all done  all handed in  don t know if mega sh...        ham"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['prediction'] = test.SMS.apply(classify_test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a prediction and a label for each item in the test set, how accurate is the spam filter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "test['correct'] = test['Label']==test['prediction']\n",
    "\n",
    "print('Accuracy: ',test.correct.sum()/len(test.correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is about 98.7% which is great!\n",
    "\n",
    "Let's look at the messages that were classified incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Label                                                SMS\n",
      "114  spam  not heard from u4 a while  call me now am here...\n",
      "135  spam  more people are dogging in your area now  call...\n",
      "152   ham                  unlimited texts  limited minutes \n",
      "159   ham                                       26th of july\n",
      "284   ham                             nokia phone is lovly  \n",
      "293   ham  a boy loved a gal  he propsd bt she didnt mind...\n",
      "302   ham                   no calls  messages  missed calls\n",
      "319   ham  we have sent jd for customer service cum accou...\n",
      "504  spam  oh my god  i ve found your number again  i m s...\n",
      "546  spam  hi babe its chloe  how r u  i was smashed on s...\n",
      "741  spam  0a networks allow companies to bill for sms  s...\n",
      "876  spam           rct  thnq adrian for u text  rgds vatian\n",
      "885  spam                                      2 2 146tf150p\n",
      "953  spam  hello  we need some posh birds and chaps to us...\n"
     ]
    }
   ],
   "source": [
    "print(test[~test.correct][['Label','SMS']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In this project, we built a spam filter that correctly identified 98.7% of messages in our test data. \n",
    "\n",
    "Next steps could include diagnosing the issues that caused incorrect classifications. We can see that the filter made mistakes on both true ham and true spam, so it would be interesting to understand what causes these issues."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
